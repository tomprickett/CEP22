%%
%% This is file `sample-sigconf.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `sigconf')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% The first command in your LaTeX source must be the \documentclass command.
\documentclass[sigconf, anonymous=true]{acmart}
%%note: adding authors will make over 4 pages - removing arXiv from refererences %% will resolved
\settopmatter{authorsperrow=3}
%% NOTE that a single column version may be required for 
%% submission and peer review. This can be done by changing
%% the \doucmentclass[...]{acmart} in this template to 
%% \documentclass[manuscript,screen]{acmart}
%% 
%% To ensure 100% compatibility, please check the white list of
%% approved LaTeX packages to be used with the Master Article Template at
%% https://www.acm.org/publications/taps/whitelist-of-latex-packages 
%% before creating your document. The white list page provides 
%% information on how to submit additional LaTeX packages for 
%% review and adoption.
%% Fonts used in the template cannot be substituted; margin 
%% adjustments are not allowed.
%%
%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmcopyright}
\copyrightyear{2022}
\acmYear{2022}
\acmDOI{10.1145/1122445.1122456}

%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[CEP '22]{CEP '22: ACM Computing Education Practice}{January 06, 2022}{Durham, UK}
\acmBooktitle{CEP '22: ACM Computing Education Practice Conference,
  January 06, 2022, Durham, UK}
\acmPrice{15.00}
\acmISBN{978-1-4503-XXXX-X/18/06}


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Gender parity in peer assessment of team software development projects}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
\author{Tom Crick}
\orcid{0000-0001-5196-9389}
\affiliation{%
\institution{Swansea University}
\city{Swansea}
\country{UK}
 }
\email{thomas.crick@swansea.ac.uk}


\author{Tom Prickett}
\affiliation{%
 \institution{ Northumbria University}
 \city{Newcastle upon Tyne}
 \country{UK}
 }
\email{tom.prickett@northumbria.ac.uk}

\author{Jill Bradnum}
\affiliation{%
	\institution{ Northumbria University}
	\city{Newcastle upon Tyne}
	\country{UK}
}
\email{jill.bradnum@northumbria.ac.uk}

\author{Alan Godfrey}
\affiliation{%
	\institution{ Northumbria University}
	\city{Newcastle upon Tyne}
	\country{UK}
}
\email{alan.godfrey@northumbria.ac.uk}
%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Crick and Prickett, et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
  Development projects in which small teams of learners build software / digital products are very common features of computing related degree programmes. It is a challenge to ensure students are fairly rewarded for the extent of the contribution they make to the collective team effort within these projects. Maintaining gender parity within assessment processes is always critical.  Assuring gender parity in the measurement of contribution to collective endeavour is clearly a critical aspect of fairness in the assessment of team-based projects. This paper presents the process within one such project which uses the Team-Q metric \cite{Britton2017} and analyses the impact of the self-declared gender of marking and marked peer on the scores obtained. The results are indicative of the scheme in this context displaying gender parity.  The paper makes the case for continued vigilance in this area to ensure Team-Q and other schemes are used in a context that support gender parity.    
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10003456.10003457.10003527</concept_id>
       <concept_desc>Social and professional topics~Computing education</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10003456.10003457.10003527.10003540</concept_id>
       <concept_desc>Social and professional topics~Student assessment</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Social and professional topics~Computing education}
\ccsdesc[500]{Social and professional topics~Student assessment}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{computing education, peer assessment, diversity, gender}
%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle
\section{What is it?}	
%%A short description of the practice you're presenting
\label{sec:What}
In the United Kingdom (UK) and other jurisdictions Computing degrees regularly contain courses in which teams of learners develop software / digital products. Commonly this enables the development or enhancement of various software engineering competencies for example; analysis and design; implementation; testing; configuration management / version control; team work; project management / control etc. Such teamwork projects are not universally well received by all students \cite{Gordon2010}, however there is an employment related dimension \cite{Thomas2003} to the development of these competencies and they are required inclusions by the related professional bodies\cite{Crick2020}. 

Within these team projects, all members of the teams are expected to contribute to the  development of software / digital products. Sometimes the contribution is structured in some manner by task, by role etc, in other projects the teams are more self-managing. Commonly, there will be some expected collective outcomes. These outcomes could be a product (e.g. common-look and feel, an integrated product, etc.) or task based (e.g. risk analysis, project plan, team demonstration of the product, etc.).  In addition to the collective tasks there may be individual tasks which again could be product (e.g. building of sub-system X) or task based (e.g. testing of the product). Assuring fair contributions from all learners to collective tasks can present challenges \cite{Philips21}. One approach to address this challenge is peer assessment \cite{Gordon2010}. One common approach is for learners to indicate the relative contributions to the teamwork that delivered the project. This can be achieved by online tools such as WebPA \cite{WebPA}, or BuddyCheck.io \cite{BuddyCheck} or SparkPlus \cite{SparkPlus} or via the use of surveying tools such as Google or Microsoft forms. In many cases the learners are required to assess their peers' contributions by a set of criteria, commonly in the form of questionnaire.  In generic terms the algorithm commonly adopted is then: (1) Each learner scores each of their peers in their team by a set of metrics; (2) A weighting is then calculated by Mean Peer Score for the learner divided by Mean Peer Score for the whole team; and (3) The individual learner would then be awarded the mark that team is award multiplied by this weighting. Such team projects commonly have individual assessed outcomes as well as team responsible assessed outcomes and it would normally only be the team outcomes that would be subjected to the weighting.

Clearly the criteria used will have a significant influence on the weighting and hence potentially the grade awarded to the individual learners.  Given the number of individuals who inform the marking (i.e. all the learners) there is more potential for unconscious or conscious bias to influence the marking than if the marking was completed solely by faculty. This paper explores whether a validated, criteria namely Team Q, \cite{Britton2017} together with a specific set of practices supports gender parity in terms of the peer assessment marks awarded. 
  
The Team Q peer model produces a team work weighting via a marking scheme synthesised from wider research. In so doing it presents a comprehensive model for what constitutes effective team working. One of the outcomes is to highlight to learners a rounded model of what competencies constitute good quality team working and these are far from solely technical competencies. The authors contend this provision of a benchmark for good team working practice provides useful formative feedback for the learners as they complete the projects in their teams.

Team Q \cite{Britton2017} assesses 5 components of team working: Contributes to team project; Facilitates contributions of others; Planning and management; Fosters a Team Climate; and manages potential conflict. Each of the components is in turn measures by indication of \textit{'how often does your peer demonstrate the following}' against a set of descriptions. Each description is awarded scores as follows: Never = 0; Sometimes = 1; Usually=2; Regularly =3; and Always =4. The full set of descriptions can be seen in Table~\ref{tab:means}.  Hence a learner scores each of their peers out of 56 overall. The peer weighting is then calculated using the algorithm indicated previously ( A learner's mean peer score divided by their team's mean peer score).

\section{Why are you doing it?}
%%What happened before? What is it changing / replacing / improving? What gap is it filling?
It is commonly recognised that Science, Technology, Engineering and Mathematics (STEM) (for example \cite{Baird2018}) and more specifically computing remain male-dominated disciplines. In the UK only 1 in 5 Computing and Engineering and Technology students were female in the academic year 2019-20 \cite{HESA}. For the computing discipline, in the UK 26,285 out of 105,485 (just less than 20 \% identified as female) and 210 identified as non-binary \cite{HESA}. Addressing this imbalance is critical for the disciplines involved as is articulated in the United Nations Sustainability Goals 4 Quality Education and Goal 5 Gender Equality \cite{UN} and essential to maximise the potential future development of the discipline.

Belonging \cite{Veilleux2013} is recognised as a crucial factor for retaining learners within the computing discipline yet learners who self-identify as women have been reported to have a lower sense of belonging \cite{Mooney2020}. The challenges faced by female students related to belonging has also been qualitatively explored \cite{Winter2021}. Together, this clearly highlights the need to carefully evaluate whether education practices promote belonging, support diversity, and gender parity. Whilst there is always the need to assure equity in assessment, in this case when learners are contributing to the assessment processes of their peers the need to assure the processes used exhibits gender parity is particularly strong. 

Peer assessment is the main focus of this work, however it is acknowledged the data is being gathered as part of assessed tasks which may, in some way, influence the outcomes. Additionally, more details of the full practices adopted are provided as different results may arise if the scheme was applied in alternative assessment situations.
% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table*}[ht]
	\caption{Mean by Gender Marker Pairing}
	\begin{tabular} {| p{3cm} | p{8cm} | p{1cm}| p{1cm} | p{1cm}| p{1cm} |} 
		\hline
		
		& & \multicolumn{4}{c}{Marker Gender  / Marked Gender } \\
		\hline
		
		
		
		Component & Description & Female Female & Female Male
		& Male Female & Male Male \\
		\hline
		
		Contribute to team Project          & Participates actively and accepts a fair share of the group work                                 & 3.8                                                     & 3.444                                                 & 3.407                                                 & 3.493                                               \\
		\hline
		& Works skilfully on assigned tasks and completes them on time                                     & 3.4                                                     & 3.185                                                 & 3.444                                                 & 3.382                                               \\
		\hline
		& Gives timely, constructive feedback to team members, in the appropriate format                   & 3.2                                                     & 3.259                                                 & 3.185                                                 & 3.233                                               \\
		\hline
		Facilitates contributions of others & Communicates actively and constructively                                                         & 3.6                                                     & 3.370                                                 & 3.222                                                 & 3.378                                               \\
		\hline
		& Encourages all perspectives be considered and acknowledges contributions to others               & 3.8                                                     & 3.370                                                 & 3.333                                                 & 3.443                                               \\
		\hline
		& Constructively builds on the contributions of others and integrates own work with work of others & 3.8                                                     & 3.333                                                 & 3.296                                                 & 3.365                                               \\
		\hline
		Planning and Management             & Takes on an appropriate role in the group (e.g. leader, note take, etc)                          & 4                                                       & 2.926                                                 & 3.185                                                 & 3.057                                               \\
		\hline
		& Clarifies goals and plans the project                                                            & 3.6                                                     & 3                                                     & 3.148                                                 & 3.220                                               \\
		\hline
		& Reports to team on progress                                                                      & 3.6                                                     & 3.296                                                 & 3.333                                                 & 3.335                                               \\
		\hline
		Fosters a team climate              & Ensures consistency between words, tone, facial expressions, and body language                   & 3.6                                                     & 3.630                                                 & 3.444                                                 & 3.459                                               \\
		\hline
		& Expresses positivity and optimism about team members and project                                 & 3.4                                                     & 3.630                                                 & 3.333                                                 & 3.480                                               \\
		\hline
		Manages potential conflict          & Displays appropriate assertiveness: neither dominating, submissive nor passive aggressive        & 3.6                                                     & 3.296                                                 & 3.296                                                 & 3.426                                               \\
		\hline
		& Contributes to appropriately healthy debate                                                      & 3.6                                                     & 3.296                                                 & 3.222                                                 & 3.463                                               \\
		
		\hline
		& Responds to and manages direct/indirect conflict constructively and effectively                  & 3.6                                                     & 3.370                                                 & 3.407                                                 & 3.463                                               \\
		\hline
		& Total                                                                                                              & 50.6                                                    & 46.407                                                & 46.259                                                & 47.216                                              \\
		\hline
		& Count                                                                                                              & 5                                                       & 27                                                    & 27                                                    & 296
		\\
		\hline
	\end{tabular}
	\label{tab:means}
\end{table*}


\section{Where does it fit?}
%%A short description of your teaching context. You may, for instance, include a description of intake, class size, curriculum sequence; anything that's necessary for others to understand your situation. How do things work at your institution?
The Team Project is run as part of the final year of a Computer Science undergraduate degree at a UK-based University. The study took place in the academic year 2020-21 under the constraints of the Covid-19 pandemic. This required more virtual working than in previous deliveries. The course runs between January and April over a 15 week period including a 3 week spring vacation. Ethical approval for the study was obtained via the university ethics system.  Written consent was obtained as part of the peer assessment learners were asked to indicate "What gender do you identify as?" as an optional free text field, additionally, they were specifically requested to indicate their consent to be included in the study. Hence learners have the opportunity to not supply the information and additionally specifically consent to participate. Those who provided a null response have not been included in the study. The size of the cohort was 170. Of these 121 learners are included in the study with 108 learners self identifying as male ('male' or 'man' or 'masculine') and 13 self identifying as female. A further 3 learners identified responded as non-binary (responding: 'I don't know'; 'non-binary'; and 'nothing' ), these have not been included in the study due to the concerns they may be individually identifiable.

In brief the key aspects of the management of the projects are handled as follows:

    \textbf{Team allocation.}
The learners are allowed to either self select their teams or choose to be assigned a team. Teams are normally comprised of 5 individuals. If learners wish to be assigned a team, these are allocated randomly upon a first come, first served basis. 

\textbf {Project selection.}
All the projects are 'live' development projects in the sense that teams develop a software product for a third party. Some of the projects are self-sourced by the learners. Additionally, the tutors assist some teams in identifying suitable projects. 

\textbf{Learning Agreements.}
As part of the establishment of teams, the learners are required to produce a learning agreement which documents key decisions regarding how the team will collaborate to complete the work. Teams are encouraged to reflect upon this agreement as the projects progress. A writing frame is provided posing key questions the learning agreement should address. 

\textbf{Development approach.}
The teams are required to follow a full-stack development approach with each team member developing a subsystem that they can ultimately demonstrate individually if required. However, the teams are encouraged to demonstrate an integrated working product and are rewarded for doing so as part of the marking rubric. If presenting an integrated working product is not possible for reasons beyond an individual learner's control (for example: there is a passenger in the team) adjustments are made so that a learner is not unfairly penalised.

\textbf{Support.}
The teams are supported by weekly progress review meetings with a tutor. These  follow a stand-up style with each team member asked to identify progress and any road blocks which can then be discussed in more depth. A Microsoft Word and a InVision Freehand \cite{InVision} template were provided to support this activity. These records were uploaded to the Virtual Learning Environment at the end of meetings. External to the meetings, the supervising tutor attempted to support the teams to resolve any team related issues. For a small number of groups this involved removing a team member for serial non-engagement with either the supervision meetings or, more importantly, lack of engagement with the team.

\textbf{Assessment.}
There are three related components of summative assessment: a project proposal (10\%), a demonstration of the software (50\%) and a report which critically evaluates the project and the professional, ethical, legal and social issues a finalised and deployed version of the produced prototype would need to mitigate. The team aspects are: 50\% of the proposal and 20\% of the demonstration which are marked as as team and are weighted by peer assessment.

\textbf{Peer Assessment.}
The project proposal and the demonstration contain team and individual tasks. As such peer assessment is employed to ensure a fair split of marks between the team. Over various historical deliveries of the course various technologies have been used to administer the peer assessment including paper, virtual learning environment tools and other electronic tools. In this delivery, peer assessment was administered by Microsoft Forms. The scheme used was Team Q \cite{Britton2017}.
\section{Does it work?}	
%%How do you know? Give some evidence of effectiveness in context
The responses to Team-Q were analysed using a combination of Excel and R (version 4.1.0). Excel was primarily used for storage and data manipulation. R was used for the statistical analysis. 

The means for responses to the different descriptions in the Team-Q metric are shown in the Table~\ref{tab:means}. From the table it can be seen there appears to be little difference in the mean peer marks awarded between female marking male, male marking female or male marking male pairs (Means 46.407, 46.2259 and 47.216 respectively). This is confirmed with an Analysis of variance test (Markers Gender F-value =0.104 p=0.748 and Marked Gender F-value= 0.177 and p=0.674). Whilst the number of female to female marking pairing was relatively low, the mean is higher however it is not statistically significantly different to the other scores as can be seen from a T-Test (T-Statistic = 0.697, P = 0.487). Together this provides confidence that the peer assessment metric adopted in this case (Team-Q) appears to exhibit gender parity in terms of the gender of marker or the gender of the marked. This is a sample size of 121 learners on one course delivered with a low incidence of female to female marking but even so the results are encouraging.


\section{Who else has done this?}
%%Where did you get the idea from? (If from published reports, please include references). How did you find out about it? Was it easy/hard to adopt? What did you change?
Peer assessment and related web-based peer assessment has been advocated as a mechanism for equitable assessment of contribution to team and team software development projects for a number of years \cite{Clark2005,Raban_Litchfield_2007, Gordon2010,Fagerholm, Britton2017,Philips21}. The exact mechanism varies but, as indicated previously, it frequently involves learners assessing their peers by a given metric, calculating means for individual and teams, and then weighting collective marks accordingly. It has also been reported that, when it is used in a summative context, learners sometimes do not want to award a low mark to their peers and, understandably, particularly to their friends \cite{Sridharam2003}.  Bias in peer assessment on the basis of gender has been reported \cite{Heels2019,Stonewall2018} and elsewhere bias has not been evidenced \cite{Tucker2014,Falchikov1997}. This mixed picture highlights the need to validate tools employed in different contexts to assure the process exhibits gender parity.

\section{What will you do next?}
%%Will you vary this, or develop it further?
The authors acknowledge that there are some advantages to using the existing online peer assessment tools and at the time of writing the aspiration is to employ the Team-Q regime within the BuddyCheck.io tool for the next delivery. It is possible that the remote learning required in the Covid-19 pandemic may have influenced the results, and as such the intention is to repeat the study with this year's cohort to determine if the results are reproducible in more typical learning conditions. There is the potential to extend the study to other courses at the university and potentially other courses at different institutions to explore whether the outcomes are reproducible in different circumstances. The focus of the study to date has overlooked non-binary learners due the the risks related to identification of individual learners. Consideration needs to be made for how the impact upon non-binary learners can be explored. It has been reported that self-identified minorities can have a lower sense of belonging \cite{Mooney2020}. Learners may identify as minorities for reasons other than gender (e.g. ethnicity, no family history with higher education, etc. ). Considering additional factors is an area for future work. Finally, since there are performance benefits associated with diverse teams \cite{HBR206}, exploring the impact of team diversity upon peer assessment and overall achieved grades opens up an interesting area for further exploration.


\section{Why are you telling us this?}
It is encouraging that there was evidence of gender parity within the peer assessment scheme adopted for this study. However this is for one cohort at one university, using a particular set of processes for work completed during the global Covid-19 pandemic. As such a wider investigation into the impact of alternative process (fully self managed teams for example) and whether the Team-Q criteria continues to be equitable. Arguably Team-Q is a well considered algorithm which explores more dimensions of team working than some of the more standard approaches that are embedded in existing tools such as Web-PA \cite{WebPA} or buddycheck.io \cite{BuddyCheck} or SparkPlus \cite{SparkPlus}. Although such tools could easily be configured to use the Team-Q scheme or other scheme as an alternative to their default.

Given the low overhead of evaluating the impact of self-identified gender upon peer assessment results, doing so is a practical recommendation for the occasions when peer assessment is employed.

Finally, gender parity is far from the only possible dimension of parity that should be exhibited in peer assessment and other assessment approaches. This points to a rather urgent set of work to assure assessment remains equitable (e.g. ethnicity, etc.). 

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{sample-base}



\end{document}
\endinput
%%
%% End of file `sample-sigconf.tex'.
